{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_r3MUyfgE-IQ"
   },
   "outputs": [],
   "source": [
    "path_to_csv = r\"C:\\Users\\Ayesha\\Downloads\\NN&DeepLearning_Lesson7_SourceCode (2)\\NN&DeepLearning_Lesson7_SourceCode\\diabetes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh2yYnM0Dsz7"
   },
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuzHorBiDciq",
    "outputId": "320d61d8-f32d-4ece-8d92-386e0ee08298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 12.4220 - acc: 0.6389\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5284 - acc: 0.5729\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 3.1983 - acc: 0.4792\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.2856 - acc: 0.5260\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 2.0800 - acc: 0.5625\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.8558 - acc: 0.5747\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.6899 - acc: 0.5938\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.5529 - acc: 0.6042\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.4496 - acc: 0.6128\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.3427 - acc: 0.6389\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.2558 - acc: 0.6250\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1943 - acc: 0.6458\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.1361 - acc: 0.6233\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.1461 - acc: 0.6233\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.0428 - acc: 0.6545\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 1.0239 - acc: 0.6267\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9776 - acc: 0.6372\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9613 - acc: 0.6476\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9882 - acc: 0.6267\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.9246 - acc: 0.6528\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8809 - acc: 0.6545\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8497 - acc: 0.6632\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8252 - acc: 0.6753\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8190 - acc: 0.6823\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8310 - acc: 0.6719\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7846 - acc: 0.6736\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7735 - acc: 0.6562\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.6806\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7495 - acc: 0.6892\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7666 - acc: 0.6910\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7703 - acc: 0.6892\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7399 - acc: 0.6892\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7355 - acc: 0.6771\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7335 - acc: 0.6858\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7317 - acc: 0.6753\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7336 - acc: 0.6823\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7280 - acc: 0.6649\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7124 - acc: 0.6684\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7024 - acc: 0.6823\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6942 - acc: 0.6910\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7052 - acc: 0.6753\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6950 - acc: 0.6858\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6817 - acc: 0.6875\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6967 - acc: 0.6910\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6811 - acc: 0.6944\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6796 - acc: 0.6962\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6812 - acc: 0.6840\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6613 - acc: 0.6840\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6668 - acc: 0.6840\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6561 - acc: 0.6875\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6761 - acc: 0.6944\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6600 - acc: 0.6910\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6605 - acc: 0.6875\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6742 - acc: 0.6667\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6557 - acc: 0.6753\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6524 - acc: 0.7083\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6343 - acc: 0.7083\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6470 - acc: 0.7135\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6333 - acc: 0.6979\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6334 - acc: 0.6892\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6528 - acc: 0.6823\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6233 - acc: 0.7153\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6358 - acc: 0.6910\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - acc: 0.6944\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6186 - acc: 0.6962\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6244 - acc: 0.7031\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6573 - acc: 0.6840\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6614 - acc: 0.6667\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6350 - acc: 0.7083\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6099 - acc: 0.7205\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6024 - acc: 0.7170\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6165 - acc: 0.6962\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6180 - acc: 0.7031\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6290 - acc: 0.6927\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6146 - acc: 0.7014\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6133 - acc: 0.7031\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6019 - acc: 0.7205\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5923 - acc: 0.7170\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5888 - acc: 0.7153\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5990 - acc: 0.6997\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6008 - acc: 0.7118\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5867 - acc: 0.7101\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6008 - acc: 0.7066\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - acc: 0.6892\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6143 - acc: 0.6962\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6085 - acc: 0.7135\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5910 - acc: 0.7170\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5954 - acc: 0.7066\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6106 - acc: 0.7031\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6053 - acc: 0.7170\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6227 - acc: 0.6944\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6082 - acc: 0.7049\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5837 - acc: 0.7274\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5999 - acc: 0.7205\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5851 - acc: 0.7031\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5927 - acc: 0.6875\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5848 - acc: 0.7188\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5733 - acc: 0.7188\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5857 - acc: 0.7153\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5704 - acc: 0.7101\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 20)                180       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201 (804.00 Byte)\n",
      "Trainable params: 201 (804.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6494 - acc: 0.6510\n",
      "[0.6494078040122986, 0.6510416865348816]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation  # Update the import statement\n",
    "\n",
    "# load dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv(path_to_csv, header=None).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n",
    "                                                    test_size=0.25, random_state=87)\n",
    "np.random.seed(155)\n",
    "my_first_nn = Sequential() # create model\n",
    "my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n",
    "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
    "\n",
    "#adding extra dense layers\n",
    "my_nn = Sequential()\n",
    "my_nn.add(Dense(20, input_dim=8, activation='relu'))\n",
    "my_nn.add(Dense(16, activation='relu'))  \n",
    "my_nn.add(Dense(12, activation='relu'))  \n",
    "my_nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
    "                                     initial_epoch=0)\n",
    "print(my_first_nn.summary())\n",
    "print(my_first_nn.evaluate(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
